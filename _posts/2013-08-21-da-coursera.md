---
layout: post
title: Coursera data analysis公开课笔记
---

今年年初在Coursera上学习了data analysis这门公开课，导师为约翰霍普金斯大学的Jeff Leek，之后把课堂笔记总结到evernote上了，最近发现这门课又要开了，作为复习将笔记再次整理到这里以期对比。

# 数据分析的步骤

## 定义问题

- 细化到你觉得可操作

## 定义理想数据

- 描述性的 <- 总体数据
- 探索性的 <- 有属性测量的样本数据
- 推断性的 <- 合适的总体 随机采样
- 预测性的 <- 来自同一总体 有训练集与测试集的样本
- 因果性的 <- 随机性研究
- 机械性的 <- 系统中所有组成部分的数据

## 找出你可以获得的数据

- 网络免费数据
- 购买数据
- 注意使用条款
- 数据不存在 自己创造 <- 实验

## 获得数据

- 原始数据
- 引用来源
- 网络数据注明数据来源URL与获取时间

    - www.data.gov 政府
    - http://www.gapminder.org/ 健康 卫生
    - http://www.infochimps.com/marketplace 商业数据 收费 免费都有
    - http://www.kaggle.com/ 数据科学网站可挑战
    - API

## 整理数据

- 原始数据需要整理
- 如果事先处理过要搞清楚如何处理的
- 了解数据来源
- 需要重新格式化 采样 <- 记录步骤
- 判断数据是否合适 不合适重新获取

### 数据分析文件夹的结构

>- Data
>
>   - Raw data 来自网络在Readme里注明url 描述 日期
>   - Processed data 命名体现处理过程 Readme里注明处理过程
>
>- Figures
>
>    - Exploratory figures 不必考虑装饰
>   - Final figures 只考虑装饰
>- R code
>
>   - Raw scripts 不必过分注释 版本控制 不一定用得上
>   - Final scripts 注释清晰 包括处理细节 只包括文章需要费分析
>   - R Markdown files (optional)
>- Text
>
>   - Readme files 按步骤记录清晰
>   - Text of analysis 包括前言 方法 结果 结论 讲故事 有引用

### 数据整理原则

>- 整理原则
>
>  - 每个变量为一列
>  - 每个观察样本为一行
>  - 每一个表或文件存储同一实验单位的数据
>  - 行列名通俗易懂
>  - 去除数据中明显错误
>  - 数据内部一致
>  - 增加适当的数据转化
>- 记录整理一定记录步骤

## 探索性数据分析

- 描述性总结数据
- 检查缺失值
- 绘制探索性图
- 尝试探索性分析 例如聚类

## 统计预测/建模

- 基于探索性分析
- 根据问题确定方法
- 数据转换要解释
- 测定的不确定性要考虑

## 解释结果

- 描述
- 相关
- 推断
- 预测

## 质疑结果

- 问题
- 数据源
- 处理过程
- 分析
- 结论

## 整合写出结果

- 从问题角度出发
- 形成一个故事
- 不要包含分析过程除非用来说明问题 消除质疑
- 以故事而不是时间顺序描述
- 图片要漂亮

## 写出可重复的R代码

- Rmarkdown文件

----

# 探索性数据分析


## 目的 

- 把握数据 
- 寻找模式
- 建模准备 
- 数据查错

## 注意

- 使用位置与长度来对比 
- 不要使用角度 面积（饼图）
- 不要使用3D图 不直观
- 绘图步骤 

    - 粗图-精细化-存储-展示

## 分层聚类

- 找到最近的 聚到一起 找下个最近的

- 给出距离范围与距离计算方法

    - 欧氏距离 多维空间点距 开平方
    - manhattan距离 出租车距离 绝对值

- tips

    - 给出变量间或样本间的关系
    - 图形可能不稳定 多少样本多少类
    - 结果是确定的
    - 选定cut点并不明显
    - 应该首先用来探索

## k-means聚类

- 固定聚类数 给出聚类中心 寻找最近的点 循环

- 需要聚类数与聚类距离范围

- tips

    - 需要大量聚类 通过眼睛 交叉检验
    - k的经验数值  或者根据解释的变量变化多少来选取
    - 结果不确定 根据聚类数与迭代次数而变化

## 主成分分析与奇异值分解

- 找到最不相关的数来解释整体方差（统计）在这些数中选取个数最少的来解释原始数据（压缩）

- SVD与PCA相通的 结果一致 都是寻找最大正交方差

- tips

    - SVD是PCA的一种解法 UDV三个向量 其中U表示行变化模式 D表示方差 V表示列变换模式 这样有助于解释主成分变化
    - 标准化与否影响结果
    - 计算量大
    - 类似探索分析还有因子分析 独立成分分析 潜在语义分析
    
----

# 统计建模

## 目的

- 寻找变量分布模式

- 寻找变量间的关系

- 对分布与关系做推断

## 最小二乘法

- 建立模型 真实值与预测值差的平方最小 求解参数

- 预测性能在中间部分预测效果好

- 用残差图表示效果

- 中心线理论 最小二乘线性回归的参数复合正态分布 方差开平方为标准误s.e.

- 自由度=样本数-估计数

- 置信区间t值

- 结果要包括方程与置信区间与p值

### p值

    -假定不相关H0假设

    -计算并检验数据

    -对比结果是否极端

        - p值可理解为计算t值时不考虑回归的影响 直接求斜率的t值 然后计算原有参数的t值 这个t值在H0中出现的概率值就是p值
        - 数据量大时容易出现随机相关进而p值显著 小心使用

## 因子变量回归

- 输出结果定量的

- 计算量化参数的均值

- 模型与线性模型一致 01分布

- 求置信区间 过0可认为差异不大

- 水平间的差异用变量系数差来表示 原因是01分布

- 求变量间关系anova 主要进行F检验 观察由变量引发的方差和是否比其他部分的方差和更大

- 如果进行多重比较 TukeyHSD法对比的是水平间的均值差异的显著性

- 因子变量回归要有参考变量

## 多元复合回归

- 考虑交互作用影响

    - 真实多元回归分析

- 混杂变量 与输入输出值都相关

- 数据转化 取对数

- 异常值 使用稳健方法 灵敏度分析 取对数

- 方差的变化 序列分析

    - 引入Box-Cox转化 方差稳定化转化 加权最小二乘法 huber-white standard errors
    - 单位变化要正态化 但要记录是否影响拟合效果与模型解释

- 相关与因果要仔细考虑背景

## 方差分析

- F检验 输出定量变量 多个探索变量 目标是确定各变量贡献

- 相关性与变量排列顺序有关

## 二项输出回归( 几率回归 )

- 结果是二元的 如 0 1

- 线性回归 lm 01得到的是可能性 p(1)/p(all)

- Odds 表示概率比 取值(0,+inf) 计算公式p/(1-p) log odds 取值(-inf,inf) 计算公式log(p/(1-p))

    - odds ratio<0.5 >2 表示有一定影响
    - 相对风险RR表示不同条件相同结果的概率比值
    - RR与OR在可能性很小的情况下一致 定义不同

- 线性回归与逻辑回归目的值一个是可能性 一个是log odds 取值更广 限制小

- 置信区间考虑过1与否

- Simpson's paradox 相关不解释因果 存在混杂变量

## 计数式输出回归

- 转换后的线性回归

- 泊松分布均值与方差一样大

- 泊松回归假设反应变量Y是泊松分布 并假设它期望值的对数可被未知参数的线性组合建模

## 模型检验与参数选择-线性回归

- 方差为常数-异方差检验

    - 寻找新的解释变量

- 可以看出线性趋势

    - 选择正确模型
    - 进行数据转换

- 变量项正确

- 没有大量异常值

    - 使用鲁棒性强的模型

- 使用默认画图观察异常值等情况

- 模型选择方法

    - Step-wise 逐步法
    - AIC 一个一个加进来
    - BIC 一个一个踢出去
    - Modern approaches: Lasso, Ridge-Regression, etc.

----

# 预测性研究设计

## 预测动机

- for glory
- rich
    http://www.heritagehealthprize.com/c/hhp
- sport
    http://www.kaggle.com/
- save lives
    http://www.oncotypedx.com/en-US/Home

## 预测步骤

- 寻找正确的数据
    - 依赖于对预测好的定义
    - 更多的数据 > 更好的算法
    - 从原始数据开始预测
    - 基准 二元预测的基准是(.5)^test size如果验证集过小 那么随机正确的可能性就越大
- 定义错误率

![](http://yufree.github.io/blogcn/figure/error.png)

- 错误测定

    - 均方误MSE 连续数据 对异常值敏感
	  - 中位数绝对偏差 连续数据 更鲁棒
	  - 灵敏度 真的为真的比率
	  - 特异性 假的为假的比率
	  - 准确性 误判的比率
	  - 一致性 kappa 系数 重复性

- 研究设计
    - 将数据分为训练集 测试集与校验集（可选）
    - 训练集需要选择特征 选择算法函数 选择交叉验证方式
    - 检验集只可应用一次 如果有校验集 可根据检验集对预测做出微调 但校验集只可应用一次
## 交叉检验

- 过拟合

    - 训练集的数据可重复优化
    - 较好的估计来自独立的检验

- 方法

    - 使用训练集
    - 将训练集拆为训练集与检验集
    - 在训练集上建模
    - 评估检验集
    - 重复求均方误

- 目的

    - 选择模型需要的变量
    - 选择模型需要的算法
    - 在预测函数里选择参数
    - 对比不同的预测集
    
- 来源一致 仿真 检验也有方差

## 回归模型

- 线性回归 lm glm

    - 预测
    - 计算RMSE
    
## 决策树

- 迭代分割变量

- 在最大化预测时分割

- 评估分支的同质性

- 多个树的预测更好

    - 优点 容易解释应用 可用在神经网络上
    - 缺点 不容易交叉验证 不确定性不宜估计 结果可能变化

-算法

    - 先在一个组里用所有的变量计算
    - 寻找最容易分离结果的变量
    - 把数据按照该变量节点分为两组
    - 在每一个组中寻找最好的分离变量
    - 迭代直到过程结束    

## 平滑

- 解决非线性问题 存在过拟合 不易解释

- 将x与y在局部位置取均值以代表这一区域 多用于时间序列分析

- 生成时间序列 然后用filter进行加权 filter参数rep(1,4)会根据side取表示4个数之和

- 对局部加权 总和为1

- losse 多项式加权 span<1 proportional to (1 - (dist/maxdist)^3)^3) span>1 α^(1/p)

- splines 样条插值平滑 矩阵模式

## bootstrap

- 将样本看成总体 有放回的反复抽样

    - 可进行假设检验
    - 可进行p值经验计算

- 不适宜进行边界值（如最值）计算 误差较大

- bootstrap prediction

    - 可用来交叉验证
    - 可用来预测回归模型错误率
    - 改善预测

## bagging

- 重采样 重新计算预测值

- 平均或投票给出结果

- 减少方差 偏差类似 适用于非线性过程

- bagged trees

    - 重采样

    - 重建树

    - 结果重评价

    - 更稳健 效果不如RF

## radom forest

- 随机采样

- 每一个节点随机选取变量

- 多棵树投票

- 准确度高 速度慢 不好解释 容易过拟合？？？

## 模型联合

- 通过平均与投票结合模型

- 联合分类器提高准确率

- 联合模型降低准确性

## mutiple testing

- 假设检验被滥用

- 两个组成部分 误差测量与矫正

- 统计学三个时代

    - 人口调查 解决重大问题 如男女比例 出生死亡率
    - Pearson Fisher Neyman Hotelling的时代 从实验结果做推断 A是否好于B
    - 科学化大规模生产 数据量大 检验强度高

- 两类错误

- I类错误 假阳性 没差异说成有差异

- II类错误 假阴性 有差异说没差异

- 错误率

    - 假阳性比率 假阳性比上实际阳性的期望 错的概率
    - Family wise error rate 假阳性个数大于1的概率
- False discovery rate 显著性错误的概率
- 置信水平alpha 如果多次假设检验错误率相当可观

### FWER

- 假设你进行m次测试 控制alpha在某水平 计算所有测试的p值 将alpha设为alpha/m 所有测试都在这个置信度下进行 
- 容易计算 过于保守

### FDR

- m次测试 水平alpha 计算p值 排序 pi<alpha*i/m
- 相对容易计算 不保守 允许一定的假阳性

### 调节p值

- pi=max m*pi pi<alpha 类似FWER处理alpha的方式处理p 按照正常alpha检测
- 一般情况 bonferroni/BH矫正就够了

## 模型检验与仿真

- 仿真可用来重采样 评价模型 检验假设 灵敏度分析

- 至少可以用来描述适用场景 不适用的场景与测试极限值

- 仿真在某些情况下丢失特征 可使用略复杂的分段仿真例如density的bw值来进行多段正态分布仿真

- 可用来解决丢失值问题 标准分布经常失效 灵敏度分析是检测多种模型的效果
